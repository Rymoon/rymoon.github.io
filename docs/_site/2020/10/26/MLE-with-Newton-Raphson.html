<!DOCTYPE html>
<html lang="en-US">
  <head>
     <meta charset="utf-8">
     
         <script type="text/x-mathjax-config">
 MathJax.Hub.Config({
     TeX: {
         equationNumbers: {
             autoNumber: "AMS"
         }
     },
     tex2jax: {
         inlineMath: [ ['$','$'] ],
         processEscapes: true,
     }
 });
 </script>
 <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
 </script>

     


<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Mle with newton raphson | Rymoon’s Website</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Mle with newton raphson" />
<meta name="author" content="stg1" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="用牛顿迭代求解MLE 数理统计的作业，顺便也贴这，但是感觉锅很多… 问题 $X_1,…, X_n \sim Gamma(\alpha,\lambda)$，$f(x,\alpha,\lambda)=\frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha−1}e^{−\lambda x}$，根据样本估计参数$\alpha,\lambda$。" />
<meta property="og:description" content="用牛顿迭代求解MLE 数理统计的作业，顺便也贴这，但是感觉锅很多… 问题 $X_1,…, X_n \sim Gamma(\alpha,\lambda)$，$f(x,\alpha,\lambda)=\frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha−1}e^{−\lambda x}$，根据样本估计参数$\alpha,\lambda$。" />
<link rel="canonical" href="http://localhost:4000/2020/10/26/MLE-with-Newton-Raphson.html" />
<meta property="og:url" content="http://localhost:4000/2020/10/26/MLE-with-Newton-Raphson.html" />
<meta property="og:site_name" content="Rymoon’s Website" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-26T00:00:00+08:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","url":"http://localhost:4000/2020/10/26/MLE-with-Newton-Raphson.html","headline":"Mle with newton raphson","dateModified":"2020-10-26T00:00:00+08:00","datePublished":"2020-10-26T00:00:00+08:00","author":{"@type":"Person","name":"stg1"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2020/10/26/MLE-with-Newton-Raphson.html"},"description":"用牛顿迭代求解MLE 数理统计的作业，顺便也贴这，但是感觉锅很多… 问题 $X_1,…, X_n \\sim Gamma(\\alpha,\\lambda)$，$f(x,\\alpha,\\lambda)=\\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha−1}e^{−\\lambda x}$，根据样本估计参数$\\alpha,\\lambda$。","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=7a3578b663bddd2f0b6135aeabdef106f9fac118">
  </head>
  <body>
    <nav>
  
    <a href="/" >Home</a>
  
    <a href="/about.html" >About</a>
  
    <a href="/blog.html" >Blog</a>
  
    <a href="/staff.html" >Staff</a>
  
</nav>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">Mle with newton raphson</h1>
      <h2 class="project-tagline">A humble website.</h2>
      
        <a href="https://github.com/Rymoon/rymoon.github.io" class="btn">View on GitHub</a>
      
      
    </header>

    <main id="content" class="main-content" role="main">
      <h1>Mle with newton raphson</h1>

<p>
  26 Oct 2020
  
  
    - <a href="/authors/stg1.html">吕之豪 崔嘉珩 肖韵竹 戴文娇</a>
  
</p>

<h1 id="用牛顿迭代求解mle">用牛顿迭代求解MLE</h1>
<p>数理统计的作业，顺便也贴这，但是感觉锅很多…</p>
<h2 id="问题">问题</h2>
<p>$X_1,…, X_n \sim Gamma(\alpha,\lambda)$，$f(x,\alpha,\lambda)=\frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha−1}e^{−\lambda x}$，根据样本估计参数$\alpha,\lambda$。</p>

<!-- more -->

<h2 id="公式推导">公式推导</h2>
<h3 id="极大似然">极大似然</h3>
<p>\(\begin{aligned}
L(\alpha,\lambda)&amp;=(\frac{\lambda^\alpha}{\Gamma(\alpha)})^n\prod_{i=1}^{n}x_i^{\alpha−1}e^{−\lambda x_i}\\
l(\alpha,\lambda)&amp;=n\alpha \ln \lambda - n\ln \Gamma(\alpha)+(\alpha-1)\sum_{i=1}^n\ln x_i-\lambda\sum_{i=1}^n x_i
\end{aligned}\)<br />
似然方程：<br />
注意到$\frac{\mathrm{d}}{\mathrm{d} x}\ln \Gamma(\alpha)$即为digamma函数$\psi(\alpha)$<br />
\(\begin{cases}
\frac{\partial l}{\partial \alpha}= n\ln \lambda-n\psi(\alpha)+\sum_{i=1}^n\ln x_i=0\\
\frac{\partial l}{\partial \lambda}=\frac{n\alpha}{\lambda}-\sum_{i=1}^n x_i=0
\end{cases}\)</p>
<h3 id="矩估计">矩估计</h3>
<p>Gamma分布的数学期望$\mu=\frac{\alpha}{\lambda},\sigma^2=\frac{\alpha}{\lambda^2}$，故$\alpha,\lambda$矩估计为$\hat{\alpha}=\frac{\overline{\mu}^2}{S_n},\hat{\lambda}=\frac{\overline{\mu}}{S_n}$</p>

<h3 id="newton-raphson算法">Newton-Raphson算法</h3>
<p>\(\begin{aligned}
\begin{bmatrix}
\hat{\alpha}^{(k+1)}\\
\hat{\lambda}^{(k+1)}
\end{bmatrix}
=\begin{bmatrix}
\hat{\alpha}^{(k)}\\
\hat{\lambda}^{(k)}
\end{bmatrix}
+H^{-1}
\begin{bmatrix}
\frac{\partial l}{\partial \alpha}(\hat{\alpha}^{(k)})\\
\frac{\partial l}{\partial \lambda}(\hat{\lambda}^{(k)})
\end{bmatrix}\\
H=-
\begin{bmatrix}
   -n\psi^{'}(\alpha) &amp; \frac{n}{\lambda} \\
   \frac{n}{\lambda} &amp; -\frac{n\alpha}{\lambda^2}
\end{bmatrix}
\end{aligned}\)</p>
<h3 id="fisher-scoring算法">Fisher Scoring算法</h3>
<p>Gamma分布是指数型分布族，$H(\hat{\theta}^{(k)})$与$x$无关，故Fisher Scoring和Newton-Raphson完全一致</p>

<h2 id="数值计算">数值计算</h2>
<h3 id="实现牛顿迭代">实现牛顿迭代</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">polygamma</span><span class="p">,</span> <span class="n">digamma</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="k">class</span> <span class="nc">Gamma</span><span class="p">:</span>
    <span class="c1"># 取alpha=5,lambda=2, 产生样本
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">lamb</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lamb</span> <span class="o">=</span> <span class="n">lamb</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="n">lamb</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">var</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># 矩估计
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">me_alpha</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">var</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">me_lambda</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">/</span> <span class="n">var</span>
    
    <span class="k">def</span> <span class="nf">Newton</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha0</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">lambda0</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
               <span class="n">iteration</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">alpha0</span> <span class="o">==</span> <span class="bp">None</span><span class="p">):</span>
            <span class="n">alpha0</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">me_alpha</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">lambda0</span> <span class="o">==</span> <span class="bp">None</span><span class="p">):</span>
            <span class="n">lambda0</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">me_lambda</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">alpha0</span><span class="p">,</span> <span class="n">lambda0</span><span class="p">])</span>
        <span class="n">tmp1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">))</span>
        <span class="n">tmp2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iteration</span><span class="p">):</span>
            <span class="c1"># Scipy中有计算digamma函数n重导数的polygamma函数，好像是用的Riemann-Zeta函数计算的
</span>            <span class="n">H</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span>
                <span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">n</span> <span class="o">*</span> <span class="n">polygamma</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="bp">self</span><span class="p">.</span><span class="n">n</span><span class="o">/</span><span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
                <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">n</span><span class="o">/</span><span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">n</span><span class="o">*</span><span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)]</span>
            <span class="p">])</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">n</span><span class="o">*</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">n</span><span class="o">*</span><span class="n">digamma</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">tmp1</span><span class="p">,</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">n</span><span class="o">*</span><span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">tmp2</span>
            <span class="p">])</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="o">-</span><span class="n">H</span><span class="p">)</span> <span class="o">@</span> <span class="n">s</span><span class="p">.</span><span class="n">T</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">verbose</span> <span class="o">==</span> <span class="mi">2</span><span class="p">):</span>
                <span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="o">-</span><span class="n">H</span><span class="p">))</span>
                <span class="k">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
                <span class="k">print</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span>
                <span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">delta</span><span class="p">))</span>
                <span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">eps</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">delta</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">eps</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">verbose</span><span class="p">):</span>
                    <span class="k">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="s">'次迭代后收敛'</span><span class="p">)</span>
                <span class="n">iteration</span> <span class="o">=</span> <span class="n">i</span>
                <span class="k">break</span>
            <span class="n">theta</span> <span class="o">+=</span> <span class="n">delta</span><span class="p">.</span><span class="n">T</span>
        <span class="k">return</span> <span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span><span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">'lambda'</span><span class="p">:</span><span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">'iteration'</span><span class="p">:</span> <span class="n">iteration</span><span class="p">}</span>
</code></pre></div></div>

<p>使用矩估计</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">Gamma</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">me_alpha</span><span class="p">,</span> <span class="n">a</span><span class="p">.</span><span class="n">me_lambda</span><span class="p">)</span>
<span class="n">a</span><span class="p">.</span><span class="n">Newton</span><span class="p">(</span><span class="n">iteration</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">eps</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>10.610932089452922 0.10720250369518106
3次迭代后收敛
{'alpha': 10.275468325113868, 'lambda': 0.1038133051654965, 'iteration': 3}
</code></pre></div></div>

<h3 id="初值影响">初值影响</h3>
<p>上面的结果是以矩估计为真实值的，结果相对而言还算可以。<br />
当初值与真实值距离较远时，如果样本量n较大，则$s(\hat{\theta_k})$较大，则会出现牛顿迭代步长过长，出现直接迭代进负数导致无法继续计算的问题。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">uniform</span>

<span class="k">def</span> <span class="nf">trail</span><span class="p">(</span><span class="n">a0_low</span><span class="p">,</span><span class="n">a0_up</span><span class="p">,</span><span class="n">l0_low</span><span class="p">,</span><span class="n">l0_up</span><span class="p">,</span><span class="n">times</span> <span class="o">=</span> <span class="mi">30</span><span class="p">):</span>
    <span class="n">success</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">times</span><span class="p">):</span>
        <span class="n">a0</span><span class="o">=</span><span class="n">uniform</span><span class="p">(</span><span class="n">a0_low</span><span class="p">,</span> <span class="n">a0_up</span><span class="p">)</span>
        <span class="n">l0</span><span class="o">=</span><span class="n">uniform</span><span class="p">(</span><span class="n">l0_low</span><span class="p">,</span> <span class="n">l0_up</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">ans</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="n">Newton</span><span class="p">(</span><span class="n">alpha0</span><span class="o">=</span><span class="n">a0</span><span class="p">,</span> <span class="n">lambda0</span><span class="o">=</span><span class="n">l0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'第'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="s">'次: alpha0'</span><span class="p">,</span><span class="n">a0</span><span class="p">,</span> <span class="s">'lambda0'</span><span class="p">,</span> <span class="n">l0</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="n">ans</span><span class="p">)</span>
            <span class="n">success</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'成功迭代率'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">success</span><span class="o">/</span><span class="n">times</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="o">+</span><span class="s">'%'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trail</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>第10次: alpha0 17.068797744939676 lambda0 0.1599353180536468
{'alpha': 10.275452639304431, 'lambda': 0.10381315181133041, 'iteration': 6}
第16次: alpha0 4.440171978099065 lambda0 0.05535445960033486
{'alpha': 10.275458241660772, 'lambda': 0.10381320573978753, 'iteration': 5}
第17次: alpha0 7.28032220854409 lambda0 0.06590695079542525
{'alpha': 10.275459583345157, 'lambda': 0.10381320559678947, 'iteration': 4}
成功迭代率10.0%
</code></pre></div></div>

<p>如上仅有一小部分迭代成功了。<br />
当随机初值的范围接近真实值时，迭代的成功率会增加很多</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trail</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mf">0.05</span><span class="p">,</span><span class="mf">0.15</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>第3次: alpha0 11.599303499919667 lambda0 0.1060487972613175
{'alpha': 10.275465254571172, 'lambda': 0.10381327602965268, 'iteration': 4}
第6次: alpha0 10.830699880799303 lambda0 0.0889107153178688
{'alpha': 10.275468323245645, 'lambda': 0.10381330514744759, 'iteration': 6}
第8次: alpha0 10.547058627260338 lambda0 0.11584305308210266
{'alpha': 10.275468196676572, 'lambda': 0.10381330368211261, 'iteration': 4}
第12次: alpha0 8.201109267478053 lambda0 0.06962384965264577
{'alpha': 10.275369505561745, 'lambda': 0.10381222849783105, 'iteration': 4}
第13次: alpha0 8.319754558610413 lambda0 0.09196506056400244
{'alpha': 10.275468270221932, 'lambda': 0.10381330462262213, 'iteration': 4}
第14次: alpha0 10.333276378689852 lambda0 0.08884530352196254
{'alpha': 10.275468320777438, 'lambda': 0.10381330512347312, 'iteration': 5}
第17次: alpha0 9.955282798221301 lambda0 0.12094191095964728
{'alpha': 10.275468315641291, 'lambda': 0.1038133050587898, 'iteration': 6}
第20次: alpha0 8.522907896117575 lambda0 0.08948649335539036
{'alpha': 10.275434353425256, 'lambda': 0.10381298493498012, 'iteration': 3}
第21次: alpha0 9.16553236111829 lambda0 0.06931782993117377
{'alpha': 10.275448520310556, 'lambda': 0.10381311192005127, 'iteration': 6}
第22次: alpha0 10.248371630585714 lambda0 0.07928943531388757
{'alpha': 10.275468321108303, 'lambda': 0.10381330512588843, 'iteration': 7}
第30次: alpha0 11.673445046376155 lambda0 0.1359823920254255
{'alpha': 10.275424223680384, 'lambda': 0.10381280469115983, 'iteration': 5}
成功迭代率36.666666666666664%
</code></pre></div></div>


      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/Rymoon/rymoon.github.io">rymoon.github.io</a> is maintained by <a href="https://github.com/Rymoon">Rymoon</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </main>
    <nav>
  
    <a href="/" >Home</a>
  
    <a href="/about.html" >About</a>
  
    <a href="/blog.html" >Blog</a>
  
    <a href="/staff.html" >Staff</a>
  
</nav>
  </body>
</html>
