{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Introduction to Machine Learning* Algorithms and Realizations 1\n",
    "\n",
    "## By Jiaheng Cui\n",
    ">In this chapter, we'll focus on an optimization method - gradient descent, and we'll explain how gradient descent works in fine-tuning models. Finally we'll introduce some revised method of gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Gradient Descent\n",
    "### (1) Basic thoughts\n",
    "Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function.\n",
    "\n",
    "We want to solve the following optimization problem:\n",
    "$$ \\mathop{\\min}\\limits_{x \\in R^n} f(x)$$\n",
    "\n",
    "Let $f(x)$ be differentiable, and $ x^{*} $ be the corresponding local minimum of $f(x)$.\n",
    "\n",
    "We'll choose a starting point $x_0$ and use the following equation to implement the iteration:\n",
    "$$x_{k+1} = x_k + step_k p_k, k = 0,1,2,...$$\n",
    "\n",
    "Where $step_k$ is the k-th step size (or learning rate), and $p_k$ is the iteration direction.\n",
    "\n",
    "In Gradient Descent, as $f(x)$ **decreases the fastest** if one goes from $x_k$ in the direction of the **negative** gradient of $f$ at $x_k$, which is $-\\nabla f(x_k)$, we'll let $p_k = -\\nabla f(x_k)$ at the k-th iteration.\n",
    "\n",
    "Then we can use line search to solve $step_k$, that is, let $step_k = \\mathop{\\arg\\min}\\limits_{step_k \\ge 0} f(x_k + step_k p_k)$. Or we can use grid search to find a fixed good step size.\n",
    "\n",
    "Note that if $f(x)$ is convex, then we have only one minimum point $x^{*}$, so the minimum we derived from gradient descent is $x^{*}$ itself (assuming there were no error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Quadratic situation\n",
    "If $f(x)$ is positive definite and quadratic, that is $$f(x) = \\frac{1}{2}x^T A x + b^T x + c, A \\gt 0$$\n",
    "\n",
    "Where $A \\gt 0$ means $A$ is positive definite, and $x$ here is a vector. Then $f(x)$ is a convex function on $R^{n \\times 1}$.\n",
    "\n",
    "Let $g_k = \\nabla f(x_k) = Ax_k + b$, then the iteration direction $p_k = -g_k$, now $x_{k+1} = x_k - step_k g_k$.\n",
    "\n",
    "Then we can derive an explicit formula of $step_k$. $step_k$ would make $f(x)$ to its minimum at direction $g_k$, so $step_k$ should be a minimizer of $\\phi(\\alpha) = f(x_k - \\alpha g_k)$.\n",
    "\n",
    "Since $\\phi'(\\alpha) = ((x_k - \\alpha g_k)^T A + b^T) (-g_k) $ and $\\phi'(step_k) = 0$, $step_k = \\frac{g_k^T g_k}{g_k^T A g_k}$. \n",
    "\n",
    "As a result, $$x_{k+1} = x_k - \\frac{g_k^T g_k}{g_k^T A g_k} g_k, g_k = Ax_k + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Algorithm\n",
    "Input: target function $f(x)$, gradient function $g(x) = \\nabla f(x)$, tolerance $\\epsilon$, starting point $x_0 \\in R^{n \\times 1}$, max iteration number $k_{max}$.\n",
    "\n",
    "Output: a minimum point of $f(x)$, $x^{*}$.\n",
    "\n",
    "Step1: load $x_0$, and set $k = 0$.\n",
    "\n",
    "Step2: calculate $f(x_k)$\n",
    "\n",
    "Step3: calculate $g_k = g(x_k)$, if $\\parallel g_k\\parallel \\lt \\epsilon$, stop iteration and let $x^* = x_k$; otherwise, let $p_k = -g_k$ and solve $step_k = \\mathop{\\arg\\min}\\limits_{step_k \\ge 0} f(x_k + step_k p_k)$.\n",
    "\n",
    "**Note: in this chapter, $\\parallel \\parallel$ means $L^2$ norm.**\n",
    "\n",
    "Step4: let $x_{k+1} = x_k + step_k p_k$, calculate $f(x_{k+1})$.\n",
    "\n",
    "Step5: if $\\parallel f(x_{k+1}) - f(x_{k})\\parallel \\lt \\epsilon$ or $\\parallel x_{k+1} - x_{k}\\parallel \\lt \\epsilon$, stop iteration and let $x^* = x_{k+1}$; otherwise, let $k = k+1$.\n",
    "\n",
    "Step6: if $k = k_{max}$, the algorithm doesn't converge, print \"Does not converge, calculation failed.\"; otherwise, return to Step3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, solving $step_k$ would be inconvenient. We'll just show two situations: fixed learning rate and quadratic situation.\n",
    "\n",
    "<1> Fixed learning rate $\\eta$ given by user, then $step_k = \\eta, k=0,1,2,...$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_fixed_eta(f_x, g_x, eps, x_0, eta, k_max):\n",
    "    x_k = x_0\n",
    "    k = 0\n",
    "    \n",
    "    for k in range(k_max + 1):#range(n) would produce a sequence: 0, 1, ..., n-1\n",
    "        g_k = g_x(x_k)\n",
    "        \n",
    "        if(np.linalg.norm(g_k) < eps):#np.linalg.norm(g_k) is the L2 norm of g_k\n",
    "            return (x_k,k)\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            p_k = - g_k\n",
    "            x_k_new = x_k + eta * p_k\n",
    "            \n",
    "            if(np.linalg.norm(f_x(x_k_new) - f_x(x_k)) < eps or np.linalg.norm(x_k_new - x_k) < eps):\n",
    "                return (x_k_new,k)\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                x_k = x_k_new\n",
    "                if(k == k_max):\n",
    "                    return \"Does not converge, calculation failed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<2> Quadratic situation, $A$ should be given by user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_quadratic(f_x, g_x, eps, x_0, A, k_max):\n",
    "    x_k = x_0\n",
    "    k = 0\n",
    "    \n",
    "    for k in range(k_max + 1):\n",
    "        g_k = g_x(x_k)\n",
    "        \n",
    "        if(np.linalg.norm(g_k) < eps):\n",
    "            return (x_k,k)\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            step_k = g_k.T.dot(g_k)/g_k.T.dot(A).dot(g_k)#.T is the action of matrix transpose, .dot() is the action of matrix multiplication\n",
    "            x_k_new = x_k - step_k * g_k\n",
    "            \n",
    "            if(np.linalg.norm(f_x(x_k_new) - f_x(x_k)) < eps or np.linalg.norm(x_k_new - x_k) < eps):\n",
    "                return (x_k_new,k)\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                x_k = x_k_new\n",
    "                if(k == k_max):\n",
    "                    return \"Does not converge, calculation failed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick test. Let $f(x_1, x_2) = x_1^2 + 4x_2^2$. Obviously $f(x)$ is convex, and the only minimum is $(0,0)$.\n",
    "\n",
    "We can convert $f(x_1, x_2)$ into its matrix form: $f(x) = \\frac{1}{2}x^T Ax, where x = (x_1,x_2)^T, A = \\left[\\begin{matrix} 2 & 0\\\\ 0 & 8\\\\ \\end{matrix}\\right] $. Then $g(x) = \\nabla f(x) = Ax$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([3.77789319e-03, 3.35544320e-18]), 24)\n",
      "(array([ 1.00365696e-03, -6.27285599e-05]), 6)\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2,0], [0,8]])\n",
    "x_0 = np.array([1,1])\n",
    "\n",
    "def f_test(x):\n",
    "    return 1/2 * x.T.dot(A).dot(x)\n",
    "\n",
    "def g_test(x):\n",
    "    return A.dot(x)\n",
    "\n",
    "print(gradient_descent_fixed_eta(f_test, g_test, 1e-5, x_0, 0.1, 1000))\n",
    "print(gradient_descent_quadratic(f_test, g_test, 1e-5, x_0, A, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, if $f(x)$ is a quadratic function, it's better to use the explicit $step_k$. The iteration number using $step_k$ is 6 while using fixed learning rate is 24.\n",
    "\n",
    "### (5) What can we do with Gradient Descent in Machine Learning?\n",
    "\n",
    "In machine learning tasks, we usually have a training set $S = \\left\\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\\right\\}, where x_i \\in R^{p \\times 1} ,y_i \\in R$, a model with parameter vector $\\theta = (\\theta_1, \\theta_2, ... ,\\theta_p)^T \\in R^{p \\times 1}$. And we want to minimize the loss function $L(\\theta) = \\frac{1}{n}\\sum_{i=1}^{n}L(f(x_i,\\theta),y_i)$.\n",
    "\n",
    "Suppose we want to train a linear model and choose MSE as our loss function:\n",
    "$$MSE(\\theta) = \\frac{1}{n} \\parallel X \\theta - y\\parallel^2= \\frac{1}{n}\\sum_{i=1}^{n}(\\theta^T x_i - y_i)^2$$\n",
    "\n",
    "Where$X = (x_1, x_2, ..., x_n)^T \\in R^{n \\times p}, y = (y_1, y_2, ..., y_n)^T \\in R^{n \\times 1}$.\n",
    "\n",
    "If we want to minimize MSE by gradient descent, we need to compute its gradient:\n",
    "$$\\nabla MSE(\\theta) = \\frac{2}{n} X^T(X\\theta-y)$$\n",
    "\n",
    "The iteration formula is $\\theta_{k+1} = \\theta_k - step_k \\nabla MSE(\\theta)$.\n",
    "\n",
    "If we put MSE and its gradient into python code, then we can use gradient descent to find the best $\\theta$ of our model. We'll use a fixed step size $\\eta$ given by the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(theta, X, y):\n",
    "    n = X.shape[0]\n",
    "    return 1/n * np.linalg.norm(X.dot(theta)-y)^2\n",
    "\n",
    "def MSE_gradient(theta, X, y):\n",
    "    n = X.shape[0]\n",
    "    return 2/n * X^T.dot(X.dot(theta)-y)\n",
    "\n",
    "def MSE_gradient_descent_fixed_eta(theta_0, X, y, eta, eps, k_max):\n",
    "    theta_k = theta_0\n",
    "    k = 0\n",
    "    \n",
    "    for k in range(k_max+1):\n",
    "        g_k = MSE_gradient(theta_k, X, y)\n",
    "        \n",
    "        if(np.linalg.norm(g_k) < eps):\n",
    "            return (theta_k,k)\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            theta_k_new = theta_k - eta * g_k\n",
    "            \n",
    "            if(np.linalg.norm(MSE(theta_k_new, X, y) - MSE(theta_k, X, y)) < eps or np.linalg.norm(theta_k_new - theta_k) < eps):\n",
    "                return (theta_k_new,k)\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                theta_k = theta_k_new\n",
    "                if(k==k_max):\n",
    "                    return \"Does not converge, calculation failed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Conjugate Gradient Descent\n",
    "### (1) Quadratic situation\n",
    "When $x_k$ is near $x^*$, especially when $f(x)$ is complicated, convergence would be slower and slower. Conjugate gradient descent can perform better when this problem occurs.\n",
    "\n",
    "Let $A$ be a positive definite matrix, $Q_1$ and $Q_2$ are two non-zero vector. Then $Q_1$ and $Q_2$ are conjugate with respect to $A$ if $Q_1^T A Q_2 = 0$.\n",
    "\n",
    "We'll still consider the quadratic problem:$$ \\mathop{\\min}\\limits_{x \\in R^n} f(x) = \\mathop{\\min}\\limits_{x \\in R^n}\\frac{1}{2}x^T A x + b^T x + c, A \\gt 0$$\n",
    "\n",
    "The iteration formula here is $x_{k+1} = x_k + \\alpha_k p_k$.\n",
    "\n",
    "Previously, $p_{k+1} = -\\nabla f(x_{k+1})$. Now we can use $step_k$ and $p_k$ to revise $p_{k+1}$:\n",
    "$$p_{k+1} =  -\\nabla f(x_{k+1}) + step_k p_k, p_0 = -\\nabla f(x_0)$$\n",
    "\n",
    "Let $p_{k+1}$ and $p_k$ be conjugate, then $0 = p_{k+1}^T A p_k = -\\nabla f(x_{k+1})A p_k + step_k p_k^TA p_k$. Then we can get $step_k = \\frac{-\\nabla f(x_{k+1})^T A p_k}{p_k^TA p_k}$.\n",
    "\n",
    "Then by line search can we get $\\alpha_k = \\frac{p_k^T(-b-Ax_k)}{p_k^T A p_k}$.\n",
    "\n",
    "As a result, in every iteration we need to first update $p_k = - \\nabla f(x_k) - \\frac{\\nabla f(x_{k})^T A p_{k-1}}{p_{k-1}^TA p_{k-1}}p_{k-1}$. Then use the new $p_k$ to calculate $\\alpha_k = \\frac{p_k^T(-b-Ax_k)}{p_k^T A p_k}$. Finally get $x_{k+1} = x_k + \\alpha_k p_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Algorithm\n",
    "Input: target function $f(x)$, gradient function $g(x) = \\nabla f(x)$, tolerance $\\epsilon$, starting point $x_0 \\in R^{n \\times 1}$, positive definite matrix $A \\in R^{n \\times n}$ used in $f(x)$, vector $b \\in R^{n \\times 1}$ used in $f(x)$, max iteration number $k_{max}$.\n",
    "\n",
    "Output: a minimum point of $f(x)$, $x^{*}$.\n",
    "\n",
    "Step1: load $x_0$, and set $k = 0$.\n",
    "\n",
    "Step2: calculate $f(x_k)$.\n",
    "\n",
    "Step3: calculate $g_k = g(x_k)$, if $\\parallel g_k\\parallel \\lt \\epsilon$, stop iteration and let $x^* = x_k$; otherwise, if $k = 0$, let $p_k = -g_k$, else if $k > 0$, let $p_k = -g_k  - \\frac{g_k^T A p_{k-1}}{p_{k-1}^TA p_{k-1}}p_{k-1}$ and solve $\\alpha_k = \\frac{p_k^T(-b-Ax_k)}{p_k^T A p_k}$.\n",
    "\n",
    "Step4: let $x_{k+1} = x_k + \\alpha_k p_k$, calculate $f(x_{k+1})$.\n",
    "\n",
    "Step5: if $\\parallel f(x_{k+1}) - f(x_{k})\\parallel \\lt \\epsilon$ or $\\parallel x_{k+1} - x_{k}\\parallel \\lt \\epsilon$, stop iteration and let $x^* = x_{k+1}$; otherwise, let $k = k+1$.\n",
    "\n",
    "Step6: if $k = k_{max}$, the algorithm doesn't converge, print \"Does not converge, calculation failed.\";otherwise, return to Step3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate_gradient_descent_quadratic(f_x, g_x, eps, x_0, A, b, k_max):\n",
    "    x_k = x_0\n",
    "    k = 0\n",
    "    p_k_old = 0 * x_0\n",
    "    \n",
    "    for k in range(k_max+1):\n",
    "        g_k = g_x(x_k)\n",
    "        \n",
    "        if(np.linalg.norm(g_k) < eps):\n",
    "            return (x_k,k)\n",
    "            break\n",
    "            \n",
    "        elif(k == 0):\n",
    "            p_k = -g_k\n",
    "            \n",
    "        elif(k > 0):\n",
    "            p_k = -g_k - g_k.T.dot(A).dot(p_k_old)/p_k_old.T.dot(A).dot(p_k_old) * p_k_old\n",
    "            \n",
    "        alpha_k = p_k.T.dot(-b-A.dot(x_k))/p_k.T.dot(A).dot(p_k)\n",
    "        x_k_new = x_k + alpha_k * p_k\n",
    "            \n",
    "        if(np.linalg.norm(f_x(x_k_new) - f_x(x_k)) < eps or np.linalg.norm(x_k_new - x_k) < eps):\n",
    "            return (x_k_new,k)\n",
    "            break\n",
    "                \n",
    "        else:\n",
    "            x_k = x_k_new\n",
    "            p_k_old = p_k\n",
    "            if(k==k_max):\n",
    "                return \"Does not converge, calculation failed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick test. Let $f(x_1, x_2) = x_1^2 - 2x_1 + 4x_2^2 - 16x_2$. Obviously $f(x)$ is convex, and the only minimum is $(1,2)$.\n",
    "\n",
    "We can convert $f(x_1, x_2)$ into its matrix form: $f(x) = \\frac{1}{2}x^T Ax + b^Tx, where x = (x_1,x_2)^T, A = \\left[\\begin{matrix} 2 & 0\\\\ 0 & 8\\\\ \\end{matrix}\\right], b = (-2, -16)^T $. Then $g(x) = \\nabla f(x) = Ax + b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.99859738, 1.99989539]), 10)\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2,0], [0,8]])\n",
    "b = np.array([-2,-16])\n",
    "x_0 = np.array([0,0])\n",
    "\n",
    "def f_test(x):\n",
    "    return 1/2 * x.T.dot(A).dot(x) + b.T.dot(x)\n",
    "\n",
    "def g_test(x):\n",
    "    return A.dot(x) + b\n",
    "\n",
    "print(conjugate_gradient_descent_quadratic(f_test, g_test, 1e-5, x_0, A, b, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Stochastic Gradient Descent\n",
    "### (1) Basic thoughts\n",
    "In part 1, we can see when computing loss function, we need to use $x_1, x_2, ..., x_n$, i.e. all samples. Hence when $n$ is large, it'll be very slow to compute loss function and its gradient.\n",
    "\n",
    "We now introduce Stochastic Gradient Descent, which only use one random sample to compute loss function and its gradient. This would make the algorithm much faster when dealing with huge training sets, and possibly to jump out of the neighborhood of a local minimum and find the global minimum. However, when it end up close to the minimum, it'll bounce around, thus never find the optimal parameter but only a relatively good parameter.\n",
    "\n",
    "We'll deal with the MSE situation. Every iteration we'll randomly pick out one $x_i$ from $X$, and corresponding $y_i$ from $y$, then input them into the following formula:\n",
    "\n",
    "$$MSE(\\theta | x_i, y_i) = (\\theta^T x_i - y_i)^2$$\n",
    "\n",
    "Then we can compute the gradient: $\\nabla MSE(\\theta | x_i, y_i) = 2(x_i^T\\theta-y_i) x_i$.\n",
    "\n",
    "The iteration formula is $\\theta_{k+1} = \\theta_k - step_k \\nabla MSE(\\theta | x_i, y_i)$. Here we'll use a simple learning schedule: $step_k = \\frac{5}{n+k+50}$, this would make step size smaller and smaller and restrain $\\theta$ from bouncing around.\n",
    "### (2) Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_one_sample(theta, x_i, y_i):\n",
    "    return np.linalg.norm(theta.T.dot(x_i)-y_i)^2\n",
    "\n",
    "def MSE_gradient_one_sample(theta, x_i, y_i):\n",
    "    return 2 * (x_i^T.dot(theta)-y_i) * x_i\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return 5/(t + 50)\n",
    "\n",
    "def MSE_stochastic_gradient_descent(theta_0, X, y, eta, eps, k_max):\n",
    "    theta_k = theta_0\n",
    "    k = 0\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for k in range(k_max+1):\n",
    "        i = np.random.randint(1, n+1)#randint(1, n+1) will produce a random integer from {1,2,...,n}\n",
    "        g_k = MSE_gradient_one_sample(theta_k, X[i], y[i])\n",
    "        \n",
    "        if(np.linalg.norm(g_k) < eps):\n",
    "            return (theta_k,k)\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            eta = learning_schedule(n + k)\n",
    "            theta_k_new = theta_k - eta * g_k\n",
    "            \n",
    "            if(np.linalg.norm(MSE_one_sample(theta_k_new, X, y) - MSE_one_sample(theta_k, X, y)) < eps or np.linalg.norm(theta_k_new - theta_k) < eps):\n",
    "                return (theta_k_new,k)\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                theta_k = theta_k_new\n",
    "                if(k==k_max):\n",
    "                    return \"Does not converge, calculation failed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Mini-batch Stochastic Gradient Descent\n",
    "### (1) Basic thoughts\n",
    "If we use small batches of samples every time to calculate loss function rather than one sample or all samples, we could somehow combine the advantages of gradient descent and stochastic gradient descent.\n",
    "\n",
    "We'll still deal with the MSE situation. Every iteration we'll randomly pick out $m (1\\le m \\le n)$ random $x_i$s (denoted as $x_{i_1},...,x_{i_m}$) from $X$, and corresponding $y_i$s (denoted as $y_{i_1},...,y_{i_m}$) from $y$. By convention we iterate by rounds of $m$ iterations, each round is called an epoch, we'll do $n_epoch$ epochs.\n",
    "\n",
    "Let $X_b = (x_{i_1},...,x_{i_m})^T \\in R^{m \\times p}, y_b = (y_{i_1},...,y_{i_m})^T \\in R^{m \\times 1}$, then input them into the following formula:\n",
    "\n",
    "$$MSE(\\theta | X_b, y_b) = \\frac{1}{m} \\parallel X_b \\theta - y_b\\parallel^2= \\frac{1}{m}\\sum_{k=1}^{m}(\\theta^T x_{i_k} - y_{i_k})^2$$\n",
    "\n",
    "Then we can compute the gradient: $$\\nabla MSE(\\theta | X_b, y_b) = \\frac{2}{m} X_b^T(X_b\\theta-y_b)$$.\n",
    "\n",
    "The iteration formula is $\\theta_{k+1} = \\theta_k - step_k \\nabla MSE(\\theta | X_b, y_b)$. Note that we'll plug the current epoch number into the learning schedule: $step_k = \\frac{5}{epoch*n+k+50}$.\n",
    "### (2) Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_m_samples_from_n(n, m):\n",
    "    if(not isinstance(m, int) or m < 1 or m > n):\n",
    "        return(\"Invalid batch size!\")\n",
    "    else:\n",
    "        L = np.array([np.random.randint(1,n+1) for _ in range(m)])# This would produce m random integer from{1,2,...,n}\n",
    "        return L\n",
    "    \n",
    "# Note that we'll use the same MSE and gradient as part 1.\n",
    "# def MSE(theta, X, y):\n",
    "#     n = X.shape[0]\n",
    "#     return 1/n * np.linalg.norm(X.dot(theta)-y)^2\n",
    "\n",
    "# def MSE_gradient(theta, X, y):\n",
    "#     n = X.shape[0]\n",
    "#     return 2/n * X^T.dot(X.dot(theta)-y)\n",
    "\n",
    "# We'll use the same learning schedule as part 3.\n",
    "# def learning_schedule(t):\n",
    "#    return 5/(t + 50)\n",
    "\n",
    "def MSE_mini_batch_stochastic_gradient_descent(theta_0, X, y, eta, eps, k_max, n_epoch):\n",
    "    theta_k = theta_0\n",
    "    k = 0\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for n in n_epoch:\n",
    "        for k in range(k_max+1):\n",
    "            L = draw_m_samples_from_n(n, m)\n",
    "            g_k = MSE_gradient(theta_k, X[L], y[L])\n",
    "        \n",
    "            if(np.linalg.norm(g_k) < eps):\n",
    "                return (theta_k,k)\n",
    "                break\n",
    "        \n",
    "            else:\n",
    "                eta = learning_schedule(n + k)\n",
    "                theta_k_new = theta_k - eta * g_k\n",
    "            \n",
    "                if(np.linalg.norm(MSE(theta_k_new, X, y) - MSE(theta_k, X, y)) < eps or np.linalg.norm(theta_k_new - theta_k) < eps):\n",
    "                    return (theta_k_new,k)\n",
    "                    break\n",
    "                \n",
    "                else:\n",
    "                    theta_k = theta_k_new\n",
    "                    if(k==k_max):\n",
    "                        return \"Does not converge, calculation failed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1.统计学习方法（第2版）- 李航\n",
    "\n",
    "2.机器学习 - 周志华\n",
    "\n",
    "3.Hands-on Machine Learning with Scikit-Learn, Keras & TensorFlow, 2nd Edition - Aurélien Géron\n",
    "\n",
    "4.Conjugate gradient method - Wikipedia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
